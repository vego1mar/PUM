{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Laboratorium nr 4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wczytywanie danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 24)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_csv_file_data(csv_file):\n",
    "    lines = []\n",
    "\n",
    "    with open(csv_file, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        header = next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            lines.append(row)\n",
    "\n",
    "    return pd.DataFrame(data=lines, columns=header)\n",
    "\n",
    "\n",
    "CSV_FILE_NAME = './../../data/RainAustralia/weatherAUS.csv'\n",
    "df_ra = read_csv_file_data(CSV_FILE_NAME)\n",
    "print(df_ra.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "del CSV_FILE_NAME"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usuwanie kolumn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                   0\n",
      "Location               0\n",
      "MinTemp                637\n",
      "MaxTemp                322\n",
      "Rainfall               1406\n",
      "Evaporation            60843\n",
      "Sunshine               67816\n",
      "WindGustDir            9330\n",
      "WindGustSpeed          9270\n",
      "WindDir9am             10013\n",
      "WindDir3pm             3778\n",
      "WindSpeed9am           1348\n",
      "WindSpeed3pm           2630\n",
      "Humidity9am            1774\n",
      "Humidity3pm            3610\n",
      "Pressure9am            14014\n",
      "Pressure3pm            13981\n",
      "Cloud9am               53657\n",
      "Cloud3pm               57094\n",
      "Temp9am                904\n",
      "Temp3pm                2726\n",
      "RainToday              1406\n",
      "RISK_MM                0\n",
      "RainTomorrow           0\n"
     ]
    }
   ],
   "source": [
    "def count_missing_values(df, missing_value='NA'):\n",
    "    header = tuple(df.columns)\n",
    "    counts = []\n",
    "\n",
    "    for i in range(0, len(header)):\n",
    "        column_name = header[i]\n",
    "        selection = df[df[column_name] == missing_value]\n",
    "        counts.append(selection.shape[0])\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "def print_missing_values_counts(df, missing):\n",
    "    header = list(df.columns)\n",
    "\n",
    "    for i in range(0, len(header)):\n",
    "        print('{h:23}{v}'.format(h=header[i], v=missing[i]))\n",
    "\n",
    "\n",
    "missing_counts = count_missing_values(df_ra)\n",
    "print_missing_values_counts(df_ra, missing_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                   0.0\n",
      "Location               0.0\n",
      "MinTemp                0.44798267143952236\n",
      "MaxTemp                0.2264527789694289\n",
      "Rainfall               0.9887969168665124\n",
      "Evaporation            42.78902618272348\n",
      "Sunshine               47.692924405561456\n",
      "WindGustDir            6.561504434114197\n",
      "WindGustSpeed          6.5193082641198945\n",
      "WindDir9am             7.041837502549352\n",
      "WindDir3pm             2.6569521706413113\n",
      "WindSpeed9am           0.948007285872019\n",
      "WindSpeed3pm           1.8495987847503041\n",
      "Humidity9am            1.247600092831574\n",
      "Humidity3pm            2.5388028946572616\n",
      "Pressure9am            9.85561877166949\n",
      "Pressure3pm            9.832410878172624\n",
      "Cloud9am               37.73533155640573\n",
      "Cloud3pm               40.15246882757942\n",
      "Temp9am                0.635755627914173\n",
      "Temp3pm                1.9171126567411898\n",
      "RainToday              0.9887969168665124\n",
      "RISK_MM                0.0\n",
      "RainTomorrow           0.0\n"
     ]
    }
   ],
   "source": [
    "def count_missing_percent(missing, total):\n",
    "    percents = []\n",
    "\n",
    "    for i in range(0, len(missing)):\n",
    "        percentage = float((missing[i] / total) * 100)\n",
    "        percents.append(percentage)\n",
    "\n",
    "    return percents\n",
    "\n",
    "\n",
    "missing_percent = count_missing_percent(missing_counts, df_ra.shape[0])\n",
    "print_missing_values_counts(df_ra, missing_percent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'RISK_MM']\n"
     ]
    }
   ],
   "source": [
    "def list_of_labels_to_be_deleted(df, percents, greater_than=30):\n",
    "    header = tuple(df.columns)\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(percents)):\n",
    "        if percents[i] > greater_than:\n",
    "            labels.append(header[i])\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "invalid_columns = list_of_labels_to_be_deleted(df_ra, missing_percent)\n",
    "invalid_columns.append('RISK_MM')\n",
    "print(invalid_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 19)\n"
     ]
    }
   ],
   "source": [
    "def delete_invalid_columns(df, invalids):\n",
    "    df.drop(invalids, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "delete_invalid_columns(df_ra, invalid_columns)\n",
    "print(df_ra.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "del invalid_columns\n",
    "del missing_counts\n",
    "del missing_percent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imputacja danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "columns_to_skip = ['Date', 'Location']\n",
    "columns_categorical_str = ['WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "columns_categorical_bool = ['RainToday', 'RainTomorrow']\n",
    "columns_numerical_float = ['MinTemp', 'MaxTemp', 'Rainfall', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "columns_numerical_int = ['WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def impute_numerical_values(df, numerical, data_type, missing_value='NA'):\n",
    "    dt_num = []\n",
    "\n",
    "    for i in range(0, len(numerical)):\n",
    "        header = numerical[i]\n",
    "        column = df[df[header] != missing_value][header].astype(data_type)\n",
    "        median = column.median()\n",
    "        column = df[header].replace(missing_value, median).astype(data_type)\n",
    "        dt_num.append(column)\n",
    "\n",
    "    return dt_num\n",
    "\n",
    "\n",
    "dt_int = impute_numerical_values(df_ra, columns_numerical_int, int)\n",
    "dt_float = impute_numerical_values(df_ra, columns_numerical_float, float)\n",
    "print(len(dt_int))\n",
    "print(len(dt_float))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as scs\n",
    "\n",
    "\n",
    "def replace_bool_as_int(_column, _data_type):\n",
    "    if _data_type == int:\n",
    "        _column = _column.replace('No', 0)\n",
    "        _column = _column.replace('Yes', 1)\n",
    "\n",
    "    return _column\n",
    "\n",
    "\n",
    "def impute_categorical_values(df, categorical, data_type, missing_value='NA'):\n",
    "    _dt_cat = []\n",
    "\n",
    "    for i in range(0, len(categorical)):\n",
    "        header = categorical[i]\n",
    "        column = df[df[header] != missing_value][header]\n",
    "        column = replace_bool_as_int(column, data_type)\n",
    "        column = column.astype(data_type)\n",
    "        dominant = scs.mode(column)[0][0]\n",
    "        column = df[header].replace(missing_value, dominant)\n",
    "        column = replace_bool_as_int(column, data_type)\n",
    "        column = column.astype(data_type)\n",
    "        _dt_cat.append(column)\n",
    "\n",
    "    return _dt_cat\n",
    "\n",
    "\n",
    "dt_cat_int = impute_categorical_values(df_ra, columns_categorical_bool, int)\n",
    "dt_cat_str = impute_categorical_values(df_ra, columns_categorical_str, str)\n",
    "print(len(dt_cat_int))\n",
    "print(len(dt_cat_str))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              object\n",
      "Location          object\n",
      "WindGustDir       object\n",
      "WindDir9am        object\n",
      "WindDir3pm        object\n",
      "RainToday          int64\n",
      "RainTomorrow       int64\n",
      "WindGustSpeed      int64\n",
      "WindSpeed9am       int64\n",
      "WindSpeed3pm       int64\n",
      "Humidity9am        int64\n",
      "Humidity3pm        int64\n",
      "MinTemp          float64\n",
      "MaxTemp          float64\n",
      "Rainfall         float64\n",
      "Pressure9am      float64\n",
      "Pressure3pm      float64\n",
      "Temp9am          float64\n",
      "Temp3pm          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def add_formed_columns(df, column_names, column_series):\n",
    "    for i in range(0, len(column_names)):\n",
    "        df[column_names[i]] = column_series[i]\n",
    "\n",
    "\n",
    "def shape_new_data_frame(df):\n",
    "    headers = set(list(df.columns))\n",
    "    to_delete = headers.difference(columns_to_skip)\n",
    "    df.drop(to_delete, axis=1, inplace=True)\n",
    "    add_formed_columns(df, columns_categorical_str, dt_cat_str)\n",
    "    add_formed_columns(df, columns_categorical_bool, dt_cat_int)\n",
    "    add_formed_columns(df, columns_numerical_int, dt_int)\n",
    "    add_formed_columns(df, columns_numerical_float, dt_float)\n",
    "\n",
    "\n",
    "shape_new_data_frame(df_ra)\n",
    "print(df_ra.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = columns_numerical_int\n",
    "numerical_columns.extend(columns_numerical_float)\n",
    "categorical_columns = columns_categorical_str\n",
    "categorical_columns.extend(columns_categorical_bool)\n",
    "categorical_columns.append('Location')\n",
    "print(len(numerical_columns))\n",
    "print(len(categorical_columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "del columns_to_skip\n",
    "del columns_categorical_bool\n",
    "del columns_categorical_str\n",
    "del columns_numerical_int\n",
    "del columns_numerical_float\n",
    "del dt_cat_str\n",
    "del dt_cat_int\n",
    "del dt_float\n",
    "del dt_int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obserwacje odstające"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46213\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cut_outliers(df, numerical):\n",
    "    altered = 0\n",
    "\n",
    "    for i in range(0, len(numerical)):\n",
    "        header = numerical[i]\n",
    "        column_series = df[header]\n",
    "        q3, q1 = np.percentile(column_series, [75, 25])\n",
    "        iqr = q3 - q1\n",
    "        interval = 1.5 * iqr\n",
    "        r_outlier = q3 + interval\n",
    "        l_outlier = q1 - interval\n",
    "\n",
    "        for index, value in column_series.items():\n",
    "            if value < l_outlier:\n",
    "                df.loc[index, header] = l_outlier\n",
    "                altered += 1\n",
    "\n",
    "            if value > r_outlier:\n",
    "                df.loc[index, header] = r_outlier\n",
    "                altered += 1\n",
    "\n",
    "    return altered\n",
    "\n",
    "outliers_no = cut_outliers(df_ra, numerical_columns)\n",
    "print(outliers_no)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "del outliers_no"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalizacja i kodowanie danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 19)\n"
     ]
    }
   ],
   "source": [
    "def normalize_numerical(df, numerical):\n",
    "    _df = df.copy()\n",
    "\n",
    "    for i in range(0, len(numerical)):\n",
    "        header = numerical[i]\n",
    "        _df[header] = _df[header] / _df[header].max()\n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "df_normed = normalize_numerical(df_ra, numerical_columns)\n",
    "print(df_normed.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 115)\n"
     ]
    }
   ],
   "source": [
    "def encode_categorical(df, categorical):\n",
    "    _df = df.copy()\n",
    "\n",
    "    for i in range(0, len(categorical)):\n",
    "        header = categorical[i]\n",
    "        new_columns = pd.get_dummies(_df[header], prefix=header)\n",
    "        _df = pd.concat((_df, new_columns), axis=1)\n",
    "\n",
    "        if header != 'Location':\n",
    "            _df = _df.drop(header, axis=1)\n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "df_new = encode_categorical(df_normed, categorical_columns)\n",
    "print(df_new.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142193, 115)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def convert_date_str_to_float(df):\n",
    "    dates = []\n",
    "\n",
    "    for index, value in df['Date'].items():\n",
    "        date = datetime.datetime.fromisoformat(value)\n",
    "        time = date.timestamp()\n",
    "        dates.append(time)\n",
    "\n",
    "    dates = pd.Series(dates).astype(int)\n",
    "    df['Date'] = dates\n",
    "\n",
    "\n",
    "convert_date_str_to_float(df_new)\n",
    "print(df_new.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "         Date Location  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n0  1228086000   Albury       0.642336      0.540541      0.592593   \n1  1228172400   Albury       0.642336      0.108108      0.543210   \n2  1228258800   Albury       0.671533      0.513514      0.641975   \n3  1228345200   Albury       0.350365      0.297297      0.222222   \n4  1228431600   Albury       0.598540      0.189189      0.493827   \n\n   Humidity9am  Humidity3pm   MinTemp   MaxTemp  Rainfall  ...  \\\n0         0.71         0.22  0.437908  0.524628  0.400000  ...   \n1         0.44         0.25  0.241830  0.575029  0.000000  ...   \n2         0.38         0.30  0.421569  0.588774  0.000000  ...   \n3         0.45         0.16  0.300654  0.641466  0.000000  ...   \n4         0.82         0.33  0.571895  0.739977  0.666667  ...   \n\n   Location_Townsville  Location_Tuggeranong  Location_Uluru  \\\n0                    0                     0               0   \n1                    0                     0               0   \n2                    0                     0               0   \n3                    0                     0               0   \n4                    0                     0               0   \n\n   Location_WaggaWagga  Location_Walpole  Location_Watsonia  \\\n0                    0                 0                  0   \n1                    0                 0                  0   \n2                    0                 0                  0   \n3                    0                 0                  0   \n4                    0                 0                  0   \n\n   Location_Williamtown  Location_Witchcliffe  Location_Wollongong  \\\n0                     0                     0                    0   \n1                     0                     0                    0   \n2                     0                     0                    0   \n3                     0                     0                    0   \n4                     0                     0                    0   \n\n   Location_Woomera  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  \n\n[5 rows x 115 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>...</th>\n      <th>Location_Townsville</th>\n      <th>Location_Tuggeranong</th>\n      <th>Location_Uluru</th>\n      <th>Location_WaggaWagga</th>\n      <th>Location_Walpole</th>\n      <th>Location_Watsonia</th>\n      <th>Location_Williamtown</th>\n      <th>Location_Witchcliffe</th>\n      <th>Location_Wollongong</th>\n      <th>Location_Woomera</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1228086000</td>\n      <td>Albury</td>\n      <td>0.642336</td>\n      <td>0.540541</td>\n      <td>0.592593</td>\n      <td>0.71</td>\n      <td>0.22</td>\n      <td>0.437908</td>\n      <td>0.524628</td>\n      <td>0.400000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1228172400</td>\n      <td>Albury</td>\n      <td>0.642336</td>\n      <td>0.108108</td>\n      <td>0.543210</td>\n      <td>0.44</td>\n      <td>0.25</td>\n      <td>0.241830</td>\n      <td>0.575029</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1228258800</td>\n      <td>Albury</td>\n      <td>0.671533</td>\n      <td>0.513514</td>\n      <td>0.641975</td>\n      <td>0.38</td>\n      <td>0.30</td>\n      <td>0.421569</td>\n      <td>0.588774</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1228345200</td>\n      <td>Albury</td>\n      <td>0.350365</td>\n      <td>0.297297</td>\n      <td>0.222222</td>\n      <td>0.45</td>\n      <td>0.16</td>\n      <td>0.300654</td>\n      <td>0.641466</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1228431600</td>\n      <td>Albury</td>\n      <td>0.598540</td>\n      <td>0.189189</td>\n      <td>0.493827</td>\n      <td>0.82</td>\n      <td>0.33</td>\n      <td>0.571895</td>\n      <td>0.739977</td>\n      <td>0.666667</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 115 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "del categorical_columns\n",
    "del numerical_columns\n",
    "del df_ra\n",
    "del df_normed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Podział danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "('BadgerysCreek', 'Adelaide', 'Richmond', 'NorfolkIsland', 'Cobar', 'Moree', 'Albury', 'Dartmoor', 'Katherine', 'Wollongong', 'AliceSprings', 'SalmonGums', 'Uluru', 'SydneyAirport', 'Cairns', 'PearceRAAF', 'Portland', 'GoldCoast', 'Sydney', 'Nuriootpa', 'Woomera', 'Perth', 'Sale', 'Mildura', 'MountGambier', 'Hobart', 'Nhil', 'Walpole', 'PerthAirport', 'Darwin', 'Canberra', 'CoffsHarbour', 'MountGinini', 'NorahHead', 'Tuggeranong', 'Witchcliffe', 'Penrith', 'MelbourneAirport', 'Watsonia', 'Albany', 'Melbourne', 'Ballarat', 'Brisbane', 'Williamtown', 'Bendigo', 'Newcastle', 'Launceston', 'Townsville', 'WaggaWagga')\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as skm\n",
    "\n",
    "\n",
    "def build_and_regionalize_data(df):\n",
    "    columns = list(df.columns)\n",
    "    columns.remove('Location')\n",
    "    locations = tuple(set(df['Location']))\n",
    "    target_columns = list(set(df.columns))\n",
    "    target_columns = [x for x in target_columns if str(x).startswith('RainTomorrow')]\n",
    "    regions_data = []\n",
    "\n",
    "    for i in range(0, len(locations)):\n",
    "        city = locations[i]\n",
    "        selection = df[df['Location'] == city][columns]\n",
    "        target = selection[target_columns]\n",
    "        selection = selection.drop(target_columns, axis=1)\n",
    "        xtr, xt, ytr, yt = skm.train_test_split(selection, target, stratify=target)\n",
    "        regions_data.append([xtr, xt, ytr, yt])\n",
    "\n",
    "    return regions_data, locations\n",
    "\n",
    "\n",
    "data_regions, region_names = build_and_regionalize_data(df_new)\n",
    "print(len(region_names))\n",
    "print(region_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Klasyfikacja"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as skl\n",
    "\n",
    "\n",
    "def fit_by_regions(dt_reg):\n",
    "    fits = []\n",
    "\n",
    "    for i in range(0, len(dt_reg)):\n",
    "        model = skl.LogisticRegression()\n",
    "        x_train = dt_reg[i][0].values\n",
    "        y_train = dt_reg[i][2]['RainTomorrow_0'].values\n",
    "        model.fit(x_train, y_train)\n",
    "        fits.append(model)\n",
    "\n",
    "    return fits\n",
    "\n",
    "\n",
    "regressors = fit_by_regions(data_regions)\n",
    "print(len(regressors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "del df_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testowy zbiór krajowy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 112)\n",
      "(4900, 2)\n"
     ]
    }
   ],
   "source": [
    "import random as rnd\n",
    "\n",
    "\n",
    "def build_country_test_set(dt_reg, samples=100):\n",
    "    cardinal_set = []\n",
    "\n",
    "    for i in range(0, len(dt_reg)):\n",
    "        rows_no = dt_reg[i][1].shape[0]\n",
    "        random_indices = [rnd.randint(0, rows_no - 1) for _ in range(0, samples)]\n",
    "        x_test = dt_reg[i][1].iloc[random_indices, :]\n",
    "        y_test = dt_reg[i][3].iloc[random_indices, :]\n",
    "        cardinal_set.append([x_test, y_test])\n",
    "\n",
    "    x = cardinal_set[0][0]\n",
    "    y = cardinal_set[0][1]\n",
    "\n",
    "    for i in range(1, len(cardinal_set)):\n",
    "        x = x.append(cardinal_set[i][0], ignore_index=True)\n",
    "        y = y.append(cardinal_set[i][1], ignore_index=True)\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "country_test_cardinal = build_country_test_set(data_regions)\n",
    "print(country_test_cardinal[0].shape)\n",
    "print(country_test_cardinal[1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metryki porównawcze"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "76.59183673469387 %\n",
      "BadgerysCreek\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skt\n",
    "\n",
    "\n",
    "def country_accuracy(test_c, regs):\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(0, len(regs)):\n",
    "        x_test_c = test_c[0].values\n",
    "        y_test_c = test_c[1]['RainTomorrow_0'].values\n",
    "        y_pred = regs[i].predict(x_test_c)\n",
    "        metric = skt.accuracy_score(y_test_c, y_pred)\n",
    "        metrics.append(metric)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "country_accuracies = country_accuracy(country_test_cardinal, regressors)\n",
    "country_reg_best = np.argmax(country_accuracies)\n",
    "print(country_reg_best)\n",
    "print(country_accuracies[country_reg_best] * 100, '%')\n",
    "print(region_names[country_reg_best])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "93.18181818181817 %\n",
      "Woomera\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def regions_accuracy(dt_reg, regs):\n",
    "    metrics = []\n",
    "\n",
    "    for i in range(0, len(dt_reg)):\n",
    "        x_test_r = dt_reg[i][1].values\n",
    "        y_test_r = dt_reg[i][3]['RainTomorrow_0'].values\n",
    "        y_pred = regs[i].predict(x_test_r)\n",
    "        metric = skt.accuracy_score(y_test_r, y_pred)\n",
    "        metrics.append(metric)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "regions_accuracy = regions_accuracy(data_regions, regressors)\n",
    "regions_reg_best = np.argmax(regions_accuracy)\n",
    "print(regions_reg_best)\n",
    "print(regions_accuracy[regions_reg_best] * 100, '%')\n",
    "print(region_names[regions_reg_best])\n",
    "print(regions_reg_best == country_reg_best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- skuteczność dla całego kraju bez identyczna dla każdego regresora i można uznać, iż jest to 75 %\n",
    "- skuteczność dla poszczególnych regionów waha się, lecz nadal wynosi co najmniej 63 %\n",
    "- najprawdopodobniej przewidywanie dla całego kraju jest nadmiernie dopasowane do danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "del country_accuracies\n",
    "del regions_accuracy\n",
    "del regions_reg_best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 146]\n",
      " [  0 586]]\n",
      "\n",
      "[[   0 1147]\n",
      " [   0 3753]]\n",
      "\n",
      "80.05464480874316 %\n",
      "76.59183673469387 %\n"
     ]
    }
   ],
   "source": [
    "def region_confusion_matrix_1(dt_reg, regs, reg_idx):\n",
    "    x_test_r = dt_reg[reg_idx][1].values\n",
    "    y_test_r = dt_reg[reg_idx][3]['RainTomorrow_0'].values\n",
    "    y_pred = regs[reg_idx].predict(x_test_r)\n",
    "    cm = skt.confusion_matrix(y_test_r, y_pred)\n",
    "    score = skt.accuracy_score(y_test_r, y_pred)\n",
    "    return cm, score\n",
    "\n",
    "\n",
    "def country_confusion_matrix_2(test_c, regs, reg_idx):\n",
    "    x_test_c = test_c[0].values\n",
    "    y_test_c = test_c[1]['RainTomorrow_0'].values\n",
    "    y_pred = regs[reg_idx].predict(x_test_c)\n",
    "    cm = skt.confusion_matrix(y_test_c, y_pred)\n",
    "    score = skt.accuracy_score(y_test_c, y_pred)\n",
    "    return cm, score\n",
    "\n",
    "\n",
    "cm_region, s_region = region_confusion_matrix_1(data_regions, regressors, country_reg_best)\n",
    "cm_country, s_country = country_confusion_matrix_2(country_test_cardinal, regressors, country_reg_best)\n",
    "print(cm_region)\n",
    "print()\n",
    "print(cm_country)\n",
    "print()\n",
    "print(s_region * 100, '%')\n",
    "print(s_country * 100, '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- ostatecznie użyteczność względem zbioru krajowego, jak i zregionalizowanego jest podobna (75 %)\n",
    "- lepsze to niż nic, lecz nadal pozostawia to spory margines błędu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "del cm_country\n",
    "del cm_region\n",
    "del country_reg_best\n",
    "del country_test_cardinal\n",
    "del data_regions\n",
    "del region_names\n",
    "del regressors\n",
    "del s_country\n",
    "del s_region"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lab4.ipynb to pdf\r\n",
      "[NbConvertApp] Writing 71540 bytes to ./notebook.tex\r\n",
      "[NbConvertApp] Building PDF\r\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\r\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\r\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\r\n",
      "[NbConvertApp] PDF successfully created\r\n",
      "[NbConvertApp] Writing 63795 bytes to lab4.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf lab4.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}